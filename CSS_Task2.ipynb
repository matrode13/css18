{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSS: Politicians on Wikipedia \n",
    "\n",
    "## Which German politicians are captured on Wikipedia? Does search interest predict existence on Wikipedia?\n",
    "\n",
    "1. Create list of all German politicians between XX and XY\n",
    "2. Analyse search volume of politicians \n",
    "\t- 2.1 Plot distribution of number of countries from which search volume happens for male and female politicians\n",
    "\t- 2.2 Plot number of month during which search volume is above threshold for for male and female politicians\n",
    "3. Binary logistic regression\n",
    "\t- 3.1 Outcome variable: article exists on Wikipedia\n",
    "\t- 3.2 IV: search volume -> number of countries and month\n",
    "\t- 3.3 Control: experience (e.g. how often was a politician already part of parliament)\n",
    "\n",
    "### Answers\n",
    "\n",
    "#### Subtask 1\n",
    "1. We create a list of all Members of The Bundestag since 2005 until now (2018)\n",
    "    - Bundestag 2005-2009 (Data: https://www.abgeordnetenwatch.de/api/parliament/bundestag%202005-2009/deputies.xml)\n",
    "    - Bundestag 2009-2013 (Data: https://www.abgeordnetenwatch.de/api/parliament/bundestag%202009-2013/deputies.xml)\n",
    "    - Bundestag 2013-2017 (Data: https://www.abgeordnetenwatch.de/api/parliament/bundestag%202013-2017/deputies.xml)\n",
    "    - Bundestag 2017-     (Data: https://www.abgeordnetenwatch.de/api/parliament/bundestag/deputies.xml)\n",
    "\n",
    "A copy of the original data will be kept.\n",
    "\n",
    "\n",
    "\n",
    "The Result can be seen in data/memberList.json\n",
    "\n",
    "### Here is a sketch of the data flow\n",
    "```\n",
    "https://www.abgeordnetenwatch.de/api > parliament\n",
    "    https://www.abgeordnetenwatch.de/api/parliament/{parliament}/deputies.xml > firstName, lastName    \n",
    "        https://de.wikipedia.org/w/api.php?action=query&list=search&srsearch={firstName}%20{lastName}&format=xml \n",
    "            > pageId, title, url\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data directory where all data used will be downloaded to\n",
    "import os\n",
    "dataDirectory=\"data/\"\n",
    "if not os.path.exists(dataDirectory):\n",
    "    os.makedirs(dataDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved parliaments: data/https:__www.abgeordnetenwatch.de_api_parliaments.json\n",
      "Saved parliament: Bundestag todata/https:__www.abgeordnetenwatch.de_api_parliament_bundestag_deputies.json\n",
      "Saved parliament: Bundestag 2005-2009 todata/https:__www.abgeordnetenwatch.de_api_parliament_bundestag%202005-2009_deputies.json\n",
      "Saved parliament: Bundestag 2009-2013 todata/https:__www.abgeordnetenwatch.de_api_parliament_bundestag%202009-2013_deputies.json\n",
      "Saved parliament: Bundestag 2013-2017 todata/https:__www.abgeordnetenwatch.de_api_parliament_bundestag%202013-2017_deputies.json\n"
     ]
    }
   ],
   "source": [
    "#Solution for Task 1: Data Aquisition\n",
    "#get and data from abgeordnetenwatch.de/api to data\n",
    "import requests\n",
    "import urllib\n",
    "import os\n",
    "import json\n",
    "\n",
    "#helper function to convert url to local paths\n",
    "def toLocalPath(url):\n",
    "    return os.path.join(dataDirectory, url.replace(\"/\",\"_\"))\n",
    "\n",
    "parliamentsUrl=\"https://www.abgeordnetenwatch.de/api/parliaments.json\"\n",
    "parliamentsLocal=toLocalPath(parliamentsUrl)\n",
    "#make a local copy of the parliaments list\n",
    "urllib.request.urlretrieve(parliamentsUrl, parliamentsLocal)\n",
    "print(\"Saved parliaments: \"+ parliamentsLocal)  \n",
    "\n",
    "with open(parliamentsLocal) as parliamentsJsonFile:\n",
    "    \n",
    "    #load the local copy of the parliaments list file\n",
    "    parliaments = json.load(parliamentsJsonFile)\n",
    "\n",
    "    #iterate parliaments\n",
    "    for parliament in parliaments[\"parliaments\"]:\n",
    "        \n",
    "        #restrict to Bundestag, maybe add more alter\n",
    "        if (\"Bundestag\" in parliament[\"name\"]):\n",
    "            \n",
    "            #get the file pointing to a specific parliament\n",
    "            parliamentMembersUrl=parliamentName=parliament[\"datasets\"][\"deputies\"][\"by-name\"]\n",
    "            parliamentMembersLocal=toLocalPath(parliamentMembersUrl)\n",
    "            #make a local copy of a specific parliament\n",
    "            urllib.request.urlretrieve(parliamentMembersUrl, parliamentMembersLocal)\n",
    "            print(\"Saved parliament: \" + parliament[\"name\"] + \" to \"+ parliamentMembersLocal)            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution for Subtask 1: Purging Data\n",
    "import requests\n",
    "import urllib\n",
    "import os\n",
    "import json\n",
    "\n",
    "#the result of this subtask, a list of parliament members\n",
    "memberList = {}\n",
    "\n",
    "with open(parliamentsLocal) as parliamentsJsonFile:\n",
    "    #load the local copy of the parliaments list file\n",
    "    parliaments = json.load(parliamentsJsonFile)\n",
    "\n",
    "    #iterate parliaments\n",
    "    for parliament in parliaments[\"parliaments\"]:\n",
    "        \n",
    "        #restrict to Bundestag, maybe add more alter\n",
    "        if (\"Bundestag\" in parliament[\"name\"]):\n",
    "            \n",
    "            #get the file pointing to a specific parliament\n",
    "            parliamentMembersUrl=parliamentName=parliament[\"datasets\"][\"deputies\"][\"by-name\"]\n",
    "            parliamentMembersLocal=toLocalPath(parliamentMembersUrl)\n",
    "            \n",
    "            with open(parliamentMembersLocal) as parliamentMembersJsonFile:\n",
    "                #load local copy of the parliament file\n",
    "                parliamentMembers = json.load(parliamentMembersJsonFile)\n",
    "                for parliamentMember in parliamentMembers[\"profiles\"]:\n",
    "                    #read desired values\n",
    "                    #we use uuid as id\n",
    "                    uuid=parliamentMember[\"meta\"][\"uuid\"]\n",
    "                    firstName=parliamentMember[\"personal\"][\"first_name\"]\n",
    "                    lastName=parliamentMember[\"personal\"][\"last_name\"]\n",
    "                    gender=parliamentMember[\"personal\"][\"gender\"]\n",
    "                    \n",
    "                    #test if we already have a member with that uuid in our member list\n",
    "                    if(uuid in memberList):\n",
    "                        #update existing member entry and update the \"numberOfParliaments\"\n",
    "                        memberList[uuid][\"numberOfParliaments\"]=memberList[uuid][\"numberOfParliaments\"]+1\n",
    "                    else:\n",
    "                        #create new member entry\n",
    "                        memberList[uuid] = {\n",
    "                            \"firstName\" :firstName,\n",
    "                            \"firstName\" :firstName,\n",
    "                            \"lastName\" :lastName,\n",
    "                            \"gender\" :gender,\n",
    "                            \"numberOfParliaments\":1\n",
    "                        }\n",
    "\n",
    "#Save membrs list\n",
    "meberListJsonPath=os.path.join(dataDirectory,\"memberList.json\")\n",
    "with open(meberListJsonPath, 'w') as meberListJsonFile:\n",
    "    json.dump(memberList, meberListJsonFile, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to test if wiki page exists\n",
    "\n",
    "def wikiPageExists(fristName, lastName, language)\n",
    " #build the query string for the wiki api\n",
    "    payload = {\"action\":\"query\",\n",
    "               \"list\": \"search\",\n",
    "               \"srsearch\":\"{firstName} {lastName}\".format(firstName=firstName, lastName=lastName),\n",
    "               \"format\":\"json\"}\n",
    "    encodedPayload = urlencode(payload)\n",
    "\n",
    "    #build wikipedia api url\n",
    "    ##example document: https://de.wikipedia.org/w/api.php?action=query&list=search&srsearch=Angela+Merkel&format=json\n",
    "    wikiUrl=\"https://{language}.wikipedia.org/w/api.php?{encodedPayload}\".format(language=language, encodedPayload=encodedPayload)\n",
    "\n",
    "    result={}\n",
    "\n",
    "    #we use try to avoid errors if no such page exists\n",
    "    try:\n",
    "        wikiSearch = json.load(urllib.request.urlopen(wikiUrl))\n",
    "\n",
    "        #read the attributes and from wikipedia and put in result of the function\n",
    "        result[\"wikiTitle\"] = wikiSearch[\"query\"][\"search\"][0][\"title\"]\n",
    "        result[\"wikipageId\"] = wikiSearch[\"query\"][\"search\"][0][\"pageid\"]\n",
    "        result[\"wikipageSnippet\"] = wikiSearch[\"query\"][\"search\"][0][\"snippet\"]\n",
    "        #page exists\n",
    "        result[\"exists\"]=True\n",
    "        \n",
    "        #debug\n",
    "        #print(\"Name: {firstName} {lastName}, language: {language} pageid: {pageId}, title: {pageTitle} url: https://{language}.wikipedia.org/wiki/{pageTitleQuoted}\"\n",
    "        #      .format(firstName=firstName, lastName=lastName, language=language, pageId=pageId, pageTitle=pageTitle, pageTitleQuoted=urllib.parse.quote(pageTitle)))\n",
    "\n",
    "        #TODO check if its the right person, maybe use some categories, or search the snippet for information\n",
    "\n",
    "    except IndexError:\n",
    "        #page does not exists\n",
    "        result[\"exists\"]=False\n",
    "        #print(\"Name: {firstName} {lastName}, language: {language} does not exists!\"\n",
    "        #      .format(firstName=firstName, lastName=lastName, language=language ))\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution Subtask 2.1\n",
    "#workflow:\n",
    "#for each member in members\n",
    "#  get search volume\n",
    "#  for each language in languages\n",
    "#    test if wiki page exists\n",
    "\n",
    "import urllib\n",
    "\n",
    "#list of languages we want to test, more languages mean more time\n",
    "languages = [\"de\", \"fr\", \"nl\", \"pl\"]\n",
    "\n",
    "\n",
    "with open(meberListJsonPath) as meberListJsonFile:\n",
    "    #load the local copy of the parliaments list file\n",
    "    members = json.load(meberListJsonFile)\n",
    "    \n",
    "    for memberUuid in members:\n",
    "    \n",
    "        #TODO\n",
    "        #do google trends here, get the list of countries,\n",
    "        #above the threshold and than for each of this countires test if the wiki page exists\n",
    "    \n",
    "        for language in languages:\n",
    "\n",
    "            #get firstName and lastName to search for\n",
    "            firstName = members[memberUuid][\"firstName\"]\n",
    "            lastName = members[memberUuid][\"lastName\"]\n",
    "\n",
    "            \n",
    "            \n",
    "            #for each language we add the search volume from gogole trends and if an wikipedia page exists\n",
    "            members[memberUuid][language]={}\n",
    "\n",
    "            #TODO get search volume with suggested library\n",
    "            members[memberUuid][language][\"searchVolume\"]=1000\n",
    "\n",
    "            #get information from wikipedia\n",
    "            wikiResult=wikiPageExists(firstName, lastName, language)\n",
    "            \n",
    "            members[memberUuid][language][\"pageExists\"]=wikiResult[\"exists\"]\n",
    "            members[memberUuid][language][\"pageTitle\"]=wikiResult[\"wikiTitle\"]\n",
    "            \n",
    "         \n",
    "            \n",
    "#Save updated members list, keep old\n",
    "memberListUpdatedJsonPath=os.path.join(dataDirectory,\"memberListWikiSearch.json\")\n",
    "with open(memberListUpdatedJsonPath, 'w') as meberListUpdatedJsonFile:\n",
    "    json.dump(members,meberListUpdatedJsonFile, sort_keys=True, indent=4)\n",
    "    \n",
    "print(\"Saved updated members list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Angela Merkel</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geoName</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Samoa</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anguilla</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Antarctica</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Antigua &amp; Barbuda</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Armenia</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aruba</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austria</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azerbaijan</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bahamas</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bahrain</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bangladesh</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barbados</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belarus</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belgium</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belize</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benin</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bermuda</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bhutan</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bolivia</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosnia &amp; Herzegovina</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Botswana</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bouvet Island</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thailand</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timor-Leste</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Togo</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tokelau</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tonga</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trinidad &amp; Tobago</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tunisia</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkey</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkmenistan</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turks &amp; Caicos Islands</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuvalu</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U.S. Outlying Islands</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U.S. Virgin Islands</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uganda</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ukraine</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Arab Emirates</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uruguay</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uzbekistan</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vanuatu</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vatican City</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venezuela</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vietnam</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wallis &amp; Futuna</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western Sahara</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yemen</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zambia</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zimbabwe</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Åland Islands</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Angela Merkel\n",
       "geoName                              \n",
       "Afghanistan                         0\n",
       "Albania                            50\n",
       "Algeria                            10\n",
       "American Samoa                      0\n",
       "Andorra                             0\n",
       "Angola                              0\n",
       "Anguilla                            0\n",
       "Antarctica                          0\n",
       "Antigua & Barbuda                   0\n",
       "Argentina                           8\n",
       "Armenia                             0\n",
       "Aruba                               0\n",
       "Australia                          13\n",
       "Austria                            44\n",
       "Azerbaijan                          0\n",
       "Bahamas                             0\n",
       "Bahrain                             0\n",
       "Bangladesh                          0\n",
       "Barbados                            0\n",
       "Belarus                             0\n",
       "Belgium                            21\n",
       "Belize                              0\n",
       "Benin                               0\n",
       "Bermuda                             0\n",
       "Bhutan                              0\n",
       "Bolivia                             0\n",
       "Bosnia & Herzegovina               26\n",
       "Botswana                            0\n",
       "Bouvet Island                       0\n",
       "Brazil                              5\n",
       "...                               ...\n",
       "Thailand                            1\n",
       "Timor-Leste                         0\n",
       "Togo                                0\n",
       "Tokelau                             0\n",
       "Tonga                               0\n",
       "Trinidad & Tobago                   0\n",
       "Tunisia                            13\n",
       "Turkey                              5\n",
       "Turkmenistan                        0\n",
       "Turks & Caicos Islands              0\n",
       "Tuvalu                              0\n",
       "U.S. Outlying Islands               0\n",
       "U.S. Virgin Islands                 0\n",
       "Uganda                              0\n",
       "Ukraine                             1\n",
       "United Arab Emirates                9\n",
       "United Kingdom                     20\n",
       "United States                      10\n",
       "Uruguay                             0\n",
       "Uzbekistan                          0\n",
       "Vanuatu                             0\n",
       "Vatican City                        0\n",
       "Venezuela                           5\n",
       "Vietnam                             1\n",
       "Wallis & Futuna                     0\n",
       "Western Sahara                      0\n",
       "Yemen                               0\n",
       "Zambia                              0\n",
       "Zimbabwe                            0\n",
       "Åland Islands                       0\n",
       "\n",
       "[250 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pytrends\n",
    "from pytrends.request import TrendReq\n",
    "\n",
    "pytrends = TrendReq(hl='de-DE', tz=360)\n",
    "kw_list = [\"Angela Merkel\"]\n",
    "#cat=396 is the category for politics on google trends, sse here: https://github.com/pat310/google-trends-api/wiki/Google-Trends-Categories\n",
    "pytrends.build_payload(kw_list, cat=396, timeframe='today 5-y', geo='', gprop='')\n",
    "\n",
    "pytrends.interest_by_region(resolution='COUNTRY')\n",
    "\n",
    "#is there i way to get the geoName is country code (e.g. DE, FR)?\n",
    "#that would be way easier to handle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
